{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Transcript Analysis - Basic Usage\n",
    "\n",
    "This notebook demonstrates the basic usage of the Sales Transcript Analysis Agent.\n",
    "\n",
    "## Prerequisites\n",
    "- Azure OpenAI API credentials configured in `config/.env`\n",
    "- Milvus database running (optional for basic analysis)\n",
    "- Required packages installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.agent.transcript_analyzer import TranscriptAnalyzer\n",
    "from src.utils.config_loader import get_config\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the transcript analyzer\n",
    "analyzer = TranscriptAnalyzer()\n",
    "print(\"Transcript Analyzer initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load a Sample Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample transcript from file\n",
    "with open('../data/text/sample_transcript_1.txt', 'r') as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "print(\"Transcript loaded:\")\n",
    "print(transcript[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze the Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform full analysis\n",
    "analysis_result = analyzer.analyze_transcript(transcript)\n",
    "\n",
    "# Display results in a formatted way\n",
    "print(json.dumps(analysis_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Specific Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only requirements\n",
    "requirements = analyzer.extract_requirements(transcript)\n",
    "print(\"\\n=== REQUIREMENTS ===\")\n",
    "print(json.dumps(requirements, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations\n",
    "recommendations = analyzer.generate_recommendations(transcript)\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "print(json.dumps(recommendations, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "summary = analyzer.generate_summary(transcript)\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Multiple Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Analyze all sample transcripts\n",
    "transcript_dir = '../data/text/'\n",
    "results = {}\n",
    "\n",
    "for filename in os.listdir(transcript_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(transcript_dir, filename)\n",
    "        with open(filepath, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        print(f\"\\nAnalyzing {filename}...\")\n",
    "        result = analyzer.analyze_transcript(content)\n",
    "        results[filename] = result\n",
    "        print(f\"âœ“ {filename} analyzed successfully\")\n",
    "\n",
    "print(f\"\\nTotal transcripts analyzed: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key metrics from analysis\n",
    "if 'requirements' in analysis_result:\n",
    "    print(f\"Number of requirements identified: {len(analysis_result['requirements'])}\")\n",
    "    \n",
    "if 'recommendations' in analysis_result:\n",
    "    print(f\"Number of recommendations: {len(analysis_result['recommendations'])}\")\n",
    "    \n",
    "if 'key_points' in analysis_result:\n",
    "    print(f\"Number of key points: {len(analysis_result['key_points'])}\")\n",
    "    \n",
    "if 'action_items' in analysis_result:\n",
    "    print(f\"Number of action items: {len(analysis_result['action_items'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

